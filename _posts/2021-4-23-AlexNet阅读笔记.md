## AlexNet阅读笔记

​	这是跟着李沐大佬读paper的笔记。今天是第一篇，是2012年NeurIPS收录的[ImageNet Classification with Deep Convolutional Neural Networks (neurips.cc)](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)。这篇文章算是深度学习的经典之作，在这篇文章中提出的AlexNet也成为了经典的模型之一。

### 模型结构

<img src="F:\Hoyxl\Hoyxl.github.io\img\2021-4-23-AlexNet阅读笔记\AlexNet总体模型结构.png">

由于作者在当时所用的GPU为RTX 580，仅仅只有3G显存，因此他需要将模型切分在两张显卡上进行训练（虽然这在后来证明只要模型设计合理，3GB也足够存放模型），故此模型显得十分复杂，但实际上上下两半的内容是一致的。（另，虽然作者这种切分模型做并行训练的方法在后来的六七年里并没有得到足够的重视，但在GPU资源又变得紧缺的大模型时代，这种思想又被重新拾起）

我们从左边开始，作者首先使用$11\times11$的卷积核分别扫描一半图像，分别输入到了两个不同的GPU——GPU0和GPU1，GPU1负责下半部分，GPU0负责上半部分，随后，这里可以看到在第三次卷积时，会将上下两部分的数据进行交互，使得两半部分都能获得全局的信息，后面我们可以看到最后的全连接层也是如此，会把两半部分数据都分别给两个GPU。

我们可以注意到，矩阵的大小从原始图像的$224\times224\times3$逐步变成$55\times55\times48$，再到$13\times13\times192$，这是使得图像的空间信息逐渐被压缩，不同的特征表示被提取出来变成不同的维度，到最后变成一个长度为2048的计算机可以进行分类的数据，计算机可以根据这些特征进行分类。（通过做特征提取后，最后使用全连接，压缩为4096的向量，是很好的语义信息，机器能识别，那么他就能做很多事情。）

### 文章的其他贡献

#### 直接使用RGB原图进行分类

在这篇文章之前，大多分类的方法都需要提取特征，再使用这些特征进行分类，而这篇文章算是开山之作，直接使用卷积方法作为特征提取器，现在CV方向也多是如此。

#### 数据增强

作者的数据增强使用的是dropout方法，即每次都随机地把一些隐藏层的输出变成用50%的概率设成零，也就是每次都把一些东西设置为0 ，那么每次都有一些变化，每次都得到一个新的模型，最后变成了很多模型的融合。但是后来大家发现Dropout不是融合，目前都认为是等价一个L2 regularzation（L2正则项）。